# Video-Anomaly-Detection

Video anomaly detection (VAD) is a demanding task because the very definition of anomalies in videos is inherently inconclusive and also due to the high manpower required to supervise lengthy videos. This research paper introduces a novel method for anomaly detection in videos. It utilizes the concurrent output of two deep learning models: the Convolutional Autoencoder (ConvAE) for anomaly detection based on reconstruction errors and the Convolutional Long Short-Term Memory (ConvLSTM) for future frame prediction. The ConvAE detects anomalies by capitalizing on its excellent spatial learning capabilities and the ConvLSTM model is helpful owing to its powerful temporal modeling abilities. By running these two models in parallel and normalizing the results obtained from both, we found that our combined model (CAELSTM) gave satisfactory results (AUROC) for two of the most prevalent datasets in this field of VAD, namely CUHK Avenue (77.44%) and Ped2 (87.31%), showcasing its promising performance.
